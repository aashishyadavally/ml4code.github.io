[["ahmad2021unified", "Unified Pre-training for Program Understanding and Generation"], ["phan2021cotext", "CoTexT: Multi-task Learning with Code-Text Transformer"], ["guo2022unixcoder", "UniXcoder: Unified Cross-Modal Pre-training for Code Representation"], ["sharma2022exploratory", "An Exploratory Study on Code Attention in BERT"]]